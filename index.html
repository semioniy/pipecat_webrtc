<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Local WebRTC Voice Agent</title>
  <style>
    :root{
      --bg:#0b0f17; --panel:#111827; --text:#e5e7eb; --muted:#9ca3af;
      --border:rgba(255,255,255,.10);
      --ok:#10b981; --warn:#f59e0b; --down:#ef4444; --unk:#6b7280;
      --chip:rgba(255,255,255,.06);
      --radius:14px;
      --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      --sans: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial;
    }
    *{box-sizing:border-box}
    body{margin:0; font-family:var(--sans); background:var(--bg); color:var(--text)}
    .wrap{max-width:1100px; margin:24px auto; padding:0 16px}
    .row{display:flex; gap:14px; flex-wrap:wrap}
    .card{background:var(--panel); border:1px solid var(--border); border-radius:var(--radius); padding:14px; flex:1; min-width:280px}
    h1{margin:0 0 6px 0; font-size:20px}
    .muted{color:var(--muted)}
    .chips{display:flex; gap:8px; flex-wrap:wrap}
    .chip{display:inline-flex; align-items:center; gap:8px; padding:7px 10px; border:1px solid var(--border); border-radius:999px; background:var(--chip); font-family:var(--mono); font-size:12px}
    .dot{width:10px; height:10px; border-radius:50%}
    .dot.ok{background:var(--ok)} .dot.warn{background:var(--warn)} .dot.down{background:var(--down)} .dot.unk{background:var(--unk)}
    button{cursor:pointer; border:1px solid var(--border); background:rgba(255,255,255,.06); color:var(--text); padding:10px 12px; border-radius:10px; font-weight:600}
    button.primary{background:rgba(59,130,246,.20); border-color:rgba(59,130,246,.35)}
    button.danger{background:rgba(239,68,68,.18); border-color:rgba(239,68,68,.32)}
    .btns{display:flex; gap:10px; flex-wrap:wrap; align-items:center}
    .meter{height:10px; width:220px; background:rgba(255,255,255,.08); border:1px solid var(--border); border-radius:999px; overflow:hidden}
    .meter > div{height:100%; width:0%}
    .grid2{display:grid; grid-template-columns:1fr 1fr; gap:10px}
    label{display:block; font-size:12px; color:var(--muted); margin:6px 0 4px}
    input, textarea{
      width:100%; padding:9px 10px; border-radius:10px; border:1px solid var(--border);
      background:rgba(0,0,0,.22); color:var(--text); font-family:var(--mono); font-size:12px
    }
    textarea{min-height:72px; resize:vertical; font-family:var(--sans); font-size:13px}
    .log{height:360px; overflow:auto; padding:10px; border-radius:10px; border:1px solid var(--border); background:rgba(0,0,0,.22)}
    .line{margin:0; white-space:pre-wrap; font-family:var(--sans); font-size:14px; line-height:1.35}
    .line .who{font-family:var(--mono); font-size:12px; opacity:.9}
    .footer{margin-top:10px; display:flex; gap:10px; align-items:center; flex-wrap:wrap}
    audio{width:100%}
    @media (max-width: 900px){ .grid2{grid-template-columns:1fr} .meter{width:160px}}
  </style>
</head>
<body>
  <div class="wrap">
    <div class="row">
      <div class="card" style="flex: 2; min-width: 360px">
        <h1>Local WebRTC Voice Agent</h1>
        <div class="muted">Browser does WebRTC only. Server does health checks + transcript. No LAN scanning from this page.</div>

        <div style="height:10px"></div>

        <div class="chips">
          <div class="chip"><span class="dot unk" id="dot-llm"></span>LLM: <span id="st-llm">unknown</span></div>
          <div class="chip"><span class="dot unk" id="dot-stt"></span>STT: <span id="st-stt">unknown</span></div>
          <div class="chip"><span class="dot unk" id="dot-tts"></span>TTS: <span id="st-tts">unknown</span></div>
          <div class="chip">Phase: <span id="phase">idle</span></div>
          <div class="chip">Sessions: <span id="sessions">0</span></div>
        </div>

        <div style="height:12px"></div>

        <div class="btns">
          <button id="connect" class="primary">Connect</button>
          <button id="disconnect" class="danger" disabled>Disconnect</button>

          <span class="muted" style="margin-left:6px">Mic</span>
          <div class="meter" title="Mic level (normalized)">
            <div id="micbar"></div>
          </div>
        </div>

        <div style="height:10px"></div>
        <audio id="audio-el" autoplay></audio>

        <div class="footer">
          <button id="clear" title="Clear transcript on server">Clear transcript</button>
          <span class="muted" id="sse">SSE: disconnected</span>
        </div>
      </div>

      <div class="card" style="flex: 1; min-width: 320px">
        <h1>Config</h1>
        <div class="muted">Edits are stored on the server and applied on next reconnect.</div>

        <div class="grid2">
          <div>
            <label>LLM base URL</label>
            <input id="llm_base_url" placeholder="http://192.168.x.x:11434/v1" />
          </div>
          <div>
            <label>LLM model</label>
            <input id="llm_model" placeholder="gpt-oss:latest" />
          </div>

          <div>
            <label>STT base URL</label>
            <input id="stt_base_url" placeholder="http://192.168.x.x:8000/v1" />
          </div>
          <div>
            <label>STT model</label>
            <input id="stt_model" placeholder="Systran/faster-whisper-small" />
          </div>

          <div>
            <label>TTS base URL</label>
            <input id="tts_base_url" placeholder="http://192.168.x.x:8004/v1" />
          </div>
          <div>
            <label>TTS voice</label>
            <input id="tts_voice" placeholder="Frieren.wav" />
          </div>

          <div>
            <label>TTS model</label>
            <input id="tts_model" placeholder="gpt-4o-mini-tts" />
          </div>
          <div>
            <label>Message stream filter</label>
            <input id="accept_type" placeholder="bot-llm-text (env only)" disabled />
          </div>
        </div>

        <label>System instruction (optional)</label>
        <textarea id="system_instruction" placeholder="Leave empty to use .env default"></textarea>

        <div style="height:10px"></div>
        <div class="btns">
          <button id="save">Save config</button>
          <span class="muted" id="savehint"></span>
        </div>
      </div>
    </div>

    <div class="row" style="margin-top:14px">
      <div class="card" style="flex: 1; min-width: 360px">
        <h1>Transcript</h1>
        <div class="muted">This is server-exported clean text (not raw JSON frames).</div>
        <div style="height:10px"></div>
        <div class="log" id="log"></div>
      </div>
    </div>
  </div>

<script>
  // -----------------------------
  // Helpers
  // -----------------------------
  const $ = (id) => document.getElementById(id);

  function dotClassFrom(status){
    switch((status||"").toLowerCase()){
      case "ok": return "ok";
      case "degraded": return "warn";
      case "down": return "down";
      default: return "unk";
    }
  }

  function setHealth(which, status){
    $(`st-${which}`).textContent = status || "unknown";
    const dot = $(`dot-${which}`);
    dot.className = "dot " + dotClassFrom(status);
  }

  function appendLine(role, text){
    const p = document.createElement("p");
    p.className = "line";
    const who = document.createElement("span");
    who.className = "who";
    who.textContent = role === "user" ? "User" : "Assistant";
    p.appendChild(who);
    p.appendChild(document.createTextNode(": " + text));
    $("log").appendChild(p);
    $("log").scrollTop = $("log").scrollHeight;
  }

  // -----------------------------
  // SSE events (server-owned status)
  // -----------------------------
  let evsrc = null;

  function startSSE(){
    if(evsrc) return;
    evsrc = new EventSource("/api/events");
    $("sse").textContent = "SSE: connecting…";

    evsrc.onopen = () => $("sse").textContent = "SSE: connected";
    evsrc.onerror = () => $("sse").textContent = "SSE: disconnected";

    evsrc.onmessage = (e) => {
      let msg;
      try { msg = JSON.parse(e.data); } catch { return; }

      if(msg.type === "snapshot"){
        const st = msg.status || {};
        const health = st.health || {};
        setHealth("llm", health.llm);
        setHealth("stt", health.stt);
        setHealth("tts", health.tts);
        $("phase").textContent = (st.runtime && st.runtime.phase) || "idle";
        $("sessions").textContent = st.active_sessions ?? "0";

        const cfg = st.config || {};
        $("llm_base_url").value = cfg.llm_base_url || "";
        $("llm_model").value = cfg.llm_model || "";
        $("stt_base_url").value = cfg.stt_base_url || "";
        $("stt_model").value = cfg.stt_model || "";
        $("tts_base_url").value = cfg.tts_base_url || "";
        $("tts_model").value = cfg.tts_model || "";
        $("tts_voice").value = cfg.tts_voice || "";
        $("system_instruction").value = cfg.system_instruction || "";

        $("log").innerHTML = "";
        (msg.transcript || []).forEach(line => {
          if(typeof line !== "string") return;
          const m = line.match(/^(User|Assistant):\s*(.*)$/);
          if(m) appendLine(m[1].toLowerCase() === "user" ? "user" : "assistant", m[2]);
        });
        return;
      }

      if(msg.type === "health"){
        const health = msg.health || {};
        setHealth("llm", health.llm);
        setHealth("stt", health.stt);
        setHealth("tts", health.tts);
        return;
      }

      if(msg.type === "phase"){
        $("phase").textContent = msg.phase || "idle";
        return;
      }

      if(msg.type === "transcript"){
        appendLine(msg.role, msg.text);
        return;
      }

      if(msg.type === "transcript_clear"){
        $("log").innerHTML = "";
        return;
      }

      if(msg.type === "config"){
        $("savehint").textContent = "Saved ✓ (reconnect to apply)";
        return;
      }
    };
  }

  startSSE();

  // -----------------------------
  // Config save
  // -----------------------------
  $("save").addEventListener("click", async () => {
    $("savehint").textContent = "Saving…";
    const config = {
      llm_base_url: $("llm_base_url").value,
      llm_model: $("llm_model").value,
      stt_base_url: $("stt_base_url").value,
      stt_model: $("stt_model").value,
      tts_base_url: $("tts_base_url").value,
      tts_model: $("tts_model").value,
      tts_voice: $("tts_voice").value,
      system_instruction: $("system_instruction").value,
    };
    try{
      const r = await fetch("/api/config", {
        method:"PUT",
        headers:{ "Content-Type":"application/json" },
        body: JSON.stringify({config})
      });
      if(!r.ok){
        const t = await r.text();
        $("savehint").textContent = "Save failed: " + t;
        return;
      }
      $("savehint").textContent = "Saved ✓ (reconnect to apply)";
    }catch(e){
      $("savehint").textContent = "Save failed: " + (e?.message || e);
    }
  });

  $("clear").addEventListener("click", async () => {
    await fetch("/api/transcript/clear", {method:"POST"});
  });

  // -----------------------------
  // WebRTC connect (same semantics as the working demo)
  // -----------------------------
  const audioEl = $("audio-el");
  const micbar = $("micbar");

  let connected = false;
  let peerConnection = null;
  let audioStream = null;

  const sendIceCandidate = async (pc, candidate) => {
    await fetch('/api/offer', {
      method: "PATCH",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        pc_id: pc.pc_id,
        candidates:[{
          candidate: candidate.candidate,
          sdp_mid: candidate.sdpMid,
          sdp_mline_index: candidate.sdpMLineIndex
        }]
      })
    });
  };

  const createSmallWebRTCConnection = async (audioTrack) => {
    const config = {
      iceServers:[ { urls:"stun:stun.l.google.com:19302" } ]
    };
    const pc = new RTCPeerConnection(config);

    pc.pendingIceCandidates = [];
    pc.canSendIceCandidates = false;

    pc.ontrack = e => audioEl.srcObject = e.streams[0];

    pc.onicecandidate = async (event) => {
      if (event.candidate) {
        if (pc.canSendIceCandidates && pc.pc_id) {
          await sendIceCandidate(pc, event.candidate);
        } else {
          pc.pendingIceCandidates.push(event.candidate);
        }
      }
    };

    pc.onconnectionstatechange = () => {
      const st = pc.connectionState;
      if(st === "connected"){
        $("connect").disabled = true;
        $("disconnect").disabled = false;
      }
      if(st === "disconnected" || st === "failed" || st === "closed"){
        disconnect();
      }
    };

    // SmallWebRTCTransport expects both transceivers
    pc.addTransceiver(audioTrack, { direction: 'sendrecv' });
    pc.addTransceiver('video', { direction: 'sendrecv' });

    await pc.setLocalDescription(await pc.createOffer());
    const offer = pc.localDescription;

    const response = await fetch('/api/offer', {
      body: JSON.stringify({ sdp: offer.sdp, type: offer.type}),
      headers: { 'Content-Type': 'application/json' },
      method: 'POST',
    });

    const answer = await response.json();
    pc.pc_id = answer.pc_id;
    await pc.setRemoteDescription(answer);

    pc.canSendIceCandidates = true;
    for (const candidate of pc.pendingIceCandidates) {
      await sendIceCandidate(pc, candidate);
    }
    pc.pendingIceCandidates = [];

    return pc;
  };

  // -----------------------------
  // Mic level meter (normalized)
  // -----------------------------
  let audioCtx = null;
  let analyser = null;
  let raf = null;
  let maxRms = 0.02; // initial guess
  let maxRmsDecayAt = 0;

  function startMicMeter(stream){
    stopMicMeter();
    audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    // Some browsers start AudioContext in "suspended" even after a click.
    // Best effort resume, otherwise the analyser will read zeros.
    try{
      if(audioCtx.state === "suspended") audioCtx.resume();
    }catch{}
    analyser = audioCtx.createAnalyser();
    analyser.fftSize = 2048;

    const src = audioCtx.createMediaStreamSource(stream);
    src.connect(analyser);

    const data = new Float32Array(analyser.fftSize);

    const tick = () => {
      analyser.getFloatTimeDomainData(data);
      let sum = 0;
      for(let i=0;i<data.length;i++){
        const v = data[i];
        sum += v*v;
      }
      const rms = Math.sqrt(sum / data.length);

      // Update peak slowly (so "never crosses 50%" becomes meaningful)
      const now = performance.now();
      if(rms > maxRms){
        maxRms = rms;
        maxRmsDecayAt = now + 800; // hold peak a bit
      }else if(now > maxRmsDecayAt){
        // slow decay
        maxRms *= 0.995;
        if(maxRms < 0.02) maxRms = 0.02;
      }

      const level = Math.min(1, rms / maxRms);
      const pct = Math.round(level * 100);
      micbar.style.width = pct + "%";

      raf = requestAnimationFrame(tick);
    };
    raf = requestAnimationFrame(tick);
  }

  function stopMicMeter(){
    if(raf) cancelAnimationFrame(raf);
    raf = null;
    if(audioCtx){
      try{ audioCtx.close(); }catch{}
    }
    audioCtx = null;
    analyser = null;
    micbar.style.width = "0%";
  }

  async function connect(){
    if(connected) return;
    connected = true;
    $("connect").disabled = true;
    $("disconnect").disabled = false;

    audioStream = await navigator.mediaDevices.getUserMedia({audio: true});
    startMicMeter(audioStream);

    peerConnection = await createSmallWebRTCConnection(audioStream.getAudioTracks()[0]);
  }

  function disconnect(){
    if(!connected) return;
    connected = false;
    $("connect").disabled = false;
    $("disconnect").disabled = true;

    if(peerConnection){
      try{ peerConnection.close(); }catch{}
      peerConnection = null;
    }
    if(audioStream){
      audioStream.getTracks().forEach(t => { try{ t.stop(); }catch{} });
      audioStream = null;
    }
    stopMicMeter();
  }

  $("connect").addEventListener("click", connect);
  $("disconnect").addEventListener("click", disconnect);
</script>
</body>
</html>
